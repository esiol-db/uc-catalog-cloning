{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "\n",
    "spark = DatabricksSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_external_location_name = 'eo000_ext_loc_ctg2'\n",
    "old_catalog_name = 'eo000_ctg_ext_loc2'\n",
    "\n",
    "new_storage_credential_name = 'field_demos_credential'\n",
    "new_external_location_name = 'eo000_ext_loc_ctg5'\n",
    "new_external_location_url = 'abfss://eo000ext5@oneenvadls.dfs.core.windows.net/'\n",
    "\n",
    "new_catalog_name = 'eo000_ctg_ext_loc5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.utils import AnalysisException\n",
    "from databricks.sdk.core import DatabricksError\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service import catalog\n",
    "from typing import Dict, Any, Optional, List\n",
    "from termcolor import colored, cprint\n",
    "import re\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler = logging.FileHandler(filename=\"logs.log\", mode='w')  \n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "\n",
    "class MigrateCatalog():\n",
    "  def __init__(self, \n",
    "               old_external_location_name: str,\n",
    "               old_catalog_name: str,\n",
    "               new_storage_credential_name: str,\n",
    "               new_external_location_name: str,\n",
    "               new_external_location_url: str,\n",
    "               new_catalog_name: str,\n",
    "               db_dict: Optional[Dict[str, List]]) -> None:\n",
    "    self.w = WorkspaceClient()\n",
    "    self.old_external_location_name = old_external_location_name\n",
    "    self.old_catalog_name = old_catalog_name\n",
    "    self.new_storage_credential_name = new_storage_credential_name\n",
    "    self.new_external_location_name = new_external_location_name\n",
    "    self.new_external_location_url = new_external_location_url\n",
    "    self.new_catalog_name = new_catalog_name\n",
    "    self.db_dict = self._build_location_for_schemas(db_dict or dict())\n",
    "    self.securable_dict = {\n",
    "      catalog.SecurableType.EXTERNAL_LOCATION: [self.w.external_locations, 'External location'],\n",
    "      catalog.SecurableType.CATALOG: [self.w.catalogs, 'Catalog'],\n",
    "      catalog.SecurableType.SCHEMA: [self.w.schemas, 'Schema'],\n",
    "      catalog.SecurableType.TABLE: [self.w.tables, 'Table']\n",
    "                           }\n",
    "    \n",
    "\n",
    "  def _print_to_console(self, \n",
    "                        message: str,\n",
    "                        end: str = '\\n', \n",
    "                        indent_size: int = 1,\n",
    "                        indent_level: int = 0,\n",
    "                        color: str = None,\n",
    "                        on_color: str = None) -> None:\n",
    "    indent = ' ' * indent_size * indent_level\n",
    "    cprint(indent + message.strip(), color=color, no_color=on_color, end=end)\n",
    "\n",
    "  def _build_location_for_schemas(self, db_dict: Dict[str, List]) -> Dict[str, List]:\n",
    "    \n",
    "    db_dict_out = {}\n",
    "    if db_dict:\n",
    "      self._print_to_console('Creating external locations if they do not exist for the schemas based on the input dictionary.', color='cyan')\n",
    "    for db_name, (ext_loc_name, cred_name, url) in db_dict.items():\n",
    "      try:\n",
    "        db_external_location = self.w.external_locations.get(ext_loc_name)\n",
    "        self._print_to_console(f'External location {ext_loc_name} already exists and will be used for {db_name}.', indent_level=3)\n",
    "      except DatabricksError as e:\n",
    "        logger.info(str(e))\n",
    "        self._print_to_console(f'Creating External location {ext_loc_name} ...', indent_level=3, end=' ')\n",
    "        try:\n",
    "          db_external_location = self.w.external_locations.create(name=ext_loc_name,\n",
    "                                                        credential_name=cred_name,\n",
    "                                                        url=url)\n",
    "          self._print_to_console('DONE!', color='green')\n",
    "        \n",
    "        except AnalysisException as e:\n",
    "          logger.info(str(e))\n",
    "          self._print_to_console(str(e), color='red', on_color='on_yellow')\n",
    "      finally:\n",
    "        db_dict_out[db_name] = db_external_location.url\n",
    "    \n",
    "    return db_dict_out\n",
    "\n",
    "\n",
    "  def _migrate_tags(self, securable_type_str: str,\n",
    "                  old_catalog_name: str, \n",
    "                  new_securable_full_name: str) -> bool:\n",
    "    try:\n",
    "      securable_tag_list = spark.sql(f\"\"\"\n",
    "      SELECT * FROM \n",
    "        system.information_schema.{securable_type_str.lower()}_tags \n",
    "      WHERE catalog_name = '{old_catalog_name}'\n",
    "              \"\"\").collect()\n",
    "      \n",
    "\n",
    "      for row in securable_tag_list:\n",
    "        if securable_type_str.lower() == 'column':\n",
    "          spark.sql(f\"\"\"\n",
    "                  ALTER TABLE {new_securable_full_name}\n",
    "                  ALTER COLUMN {row.column_name}\n",
    "                  SET TAGS ('{row.tag_name}' = '{row.tag_value}')\n",
    "                  \"\"\")\n",
    "        else:\n",
    "          spark.sql(f\"\"\"\n",
    "                  ALTER {securable_type_str} {new_securable_full_name}\n",
    "                  SET TAGS ('{row.tag_name}' = '{row.tag_value}')\n",
    "                  \"\"\")\n",
    "          \n",
    "    except Exception as e:\n",
    "      logger.info(str(e))\n",
    "      self._print_to_console(str(e), color='red', on_color='on_yellow')\n",
    "\n",
    "\n",
    "  def _parse_transfer_permissions(self, \n",
    "                                  securable_type: catalog.SecurableType, \n",
    "                                  old_securable_full_name: str, \n",
    "                                  new_securable_full_name: str) -> bool:\n",
    "    try:\n",
    "      grants = self.w.grants.get(securable_type=securable_type, \n",
    "                                full_name=f'{old_securable_full_name}')\n",
    "      if grants.privilege_assignments == None:\n",
    "        return True\n",
    "      changes = []\n",
    "      for principal_permission_pair in grants.privilege_assignments:\n",
    "        principal = principal_permission_pair.principal\n",
    "        privileges = [eval(f'catalog.Privilege.{privilege}') for privilege in principal_permission_pair.privileges if (('VOL' not in privilege) and ('BROWSE' not in privilege))]\n",
    "        changes.append(catalog.PermissionsChange(add=privileges, principal=principal))\n",
    "      self.w.grants.update(full_name=new_securable_full_name, \n",
    "                          securable_type=securable_type, \n",
    "                          changes=changes)\n",
    "      return True\n",
    "    except Exception as e:\n",
    "      logger.info(str(e))\n",
    "      self._print_to_console(str(e), color='red', on_color='on_yellow')\n",
    "      return False\n",
    "  \n",
    "  def _get_or_create_transfer(self, \n",
    "                      securable_type: catalog.SecurableType, \n",
    "                      old_securable_full_name: str,\n",
    "                      new_securable_full_name: str,\n",
    "                      print_indent_level: str = 0,\n",
    "                      **kwarg) -> None:\n",
    "    new_securable = None\n",
    "    analysis_exception_hit = 0\n",
    "    new_securable_name = re.findall('[^.]+$', new_securable_full_name)[0]\n",
    "    try:\n",
    "      new_securable = self.securable_dict[securable_type][0].get(new_securable_full_name)\n",
    "      self._print_to_console(f'{self.securable_dict[securable_type][1]} {new_securable_name} already exists. Only transferring permissions, comments and tags ...', indent_level=print_indent_level, end=' ')\n",
    "    except Exception as e:\n",
    "      logger.info(str(e))\n",
    "      self._print_to_console(f'Creating {self.securable_dict[securable_type][1]} {new_securable_name} and transferring permissions, comments and tags ...', indent_level=print_indent_level, end=' ')\n",
    "      try:\n",
    "        if securable_type == catalog.SecurableType.TABLE:\n",
    "          new_securable = self.securable_dict[securable_type][0].get(old_securable_full_name)\n",
    "          spark.sql(f'CREATE TABLE {new_securable_full_name} DEEP CLONE {new_securable.full_name}')\n",
    "          new_securable = self.securable_dict[securable_type][0].get(full_name=new_securable_full_name)\n",
    "          spark.sql(f'COMMENT ON TABLE {new_securable_full_name} IS \"{new_securable.comment}\"')\n",
    "        else:\n",
    "          new_securable = self.securable_dict[securable_type][0].create(\n",
    "            name=new_securable_name,\n",
    "            comment=self.securable_dict[securable_type][0].get(old_securable_full_name).comment,\n",
    "            **kwarg)\n",
    "      except AnalysisException as ae:\n",
    "        logger.exception(ae)\n",
    "        analysis_exception_hit = 1\n",
    "        self._print_to_console(str(ae), color='red', on_color='on_yellow')\n",
    "    finally:\n",
    "      if not analysis_exception_hit:\n",
    "        _ = self._parse_transfer_permissions(securable_type=securable_type, \n",
    "                              old_securable_full_name=old_securable_full_name,\n",
    "                              new_securable_full_name=new_securable_full_name)  \n",
    "        if securable_type != catalog.SecurableType.EXTERNAL_LOCATION:     \n",
    "          _ = self._migrate_tags(self.securable_dict[securable_type][1],\n",
    "                  self.old_catalog_name, \n",
    "                  new_securable_full_name)\n",
    "        if securable_type == catalog.SecurableType.TABLE:\n",
    "          for col in new_securable.columns:\n",
    "            spark.sql(f\"\"\"\n",
    "                    ALTER TABLE {new_securable_full_name}\n",
    "                    ALTER COLUMN {col.name}\n",
    "                    COMMENT \"{col.comment}\"\n",
    "                    \"\"\")\n",
    "          _ = self._migrate_tags('column',\n",
    "                  self.old_catalog_name, \n",
    "                  new_securable_full_name)\n",
    "        self._print_to_console('DONE!', color='green')  \n",
    "    \n",
    "    return new_securable\n",
    "  \n",
    "  \n",
    "  \n",
    "  def __call__(self):\n",
    "    self._print_to_console('Creating data assets if they do not exist and migrate permissions, comments and tags.', color='cyan')\n",
    "    self.new_external_location = self._get_or_create_transfer(\n",
    "                        catalog.SecurableType.EXTERNAL_LOCATION,\n",
    "                        self.old_external_location_name,\n",
    "                        self.new_external_location_name,\n",
    "                        print_indent_level=3,\n",
    "                        credential_name=self.new_storage_credential_name,\n",
    "                        url=self.new_external_location_url)    \n",
    "\n",
    "    \n",
    "    self.new_catalog = self._get_or_create_transfer(\n",
    "                        catalog.SecurableType.CATALOG,\n",
    "                        self.old_catalog_name,\n",
    "                        self.new_catalog_name,\n",
    "                        print_indent_level=6,\n",
    "                        storage_root=self.new_external_location.url) \n",
    "         \n",
    "    \n",
    "    db_list = self.w.schemas.list(self.old_catalog_name)\n",
    "    for db in db_list:         \n",
    "      self.new_db = self._get_or_create_transfer(\n",
    "                        catalog.SecurableType.SCHEMA,\n",
    "                        f'{self.old_catalog_name}.{db.name}',\n",
    "                        f'{self.new_catalog_name}.{db.name}',\n",
    "                        print_indent_level=9,\n",
    "                        catalog_name=self.new_catalog.name,\n",
    "                        storage_root=self.db_dict.get(db.name, None))\n",
    "      \n",
    "      tbl_list = self.w.tables.list(catalog_name=self.old_catalog_name, schema_name=db.name)\n",
    "      for tbl in tbl_list:\n",
    "        if tbl.table_type == catalog.TableType.MANAGED:\n",
    "          self.new_table = self._get_or_create_transfer( \n",
    "                      catalog.SecurableType.TABLE, \n",
    "                      f'{self.old_catalog_name}.{db.name}.{tbl.name}',\n",
    "                      f'{self.new_catalog_name}.{db.name}.{tbl.name}',\n",
    "                      print_indent_level=12,)\n",
    "          \n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dict(\n",
    "    old_external_location_name = 'eo000_ext_loc_ctg2',\n",
    "    old_catalog_name = 'eo000_ctg_ext_loc2',\n",
    "    new_storage_credential_name = 'field_demos_credential',\n",
    "    new_external_location_name = 'eo000_ext_loc_ctg5',\n",
    "    new_external_location_url = 'abfss://eo000ext5@oneenvadls.dfs.core.windows.net/',\n",
    "    new_catalog_name = 'eo000_ctg_ext_loc5')\n",
    "\n",
    "db_dict = {\n",
    "    'db1': ['eo000_ext_db_loc01', 'field_demos_credential', 'abfss://eo000extdb0@oneenvadls.dfs.core.windows.net/'],\n",
    "    'db2': ['eo000_ext_db_loc01', 'field_demos_credential', 'abfss://eo000extdb0@oneenvadls.dfs.core.windows.net/'],\n",
    "    'db_empty': ['eo000_ext_db_loc02', 'field_demos_credential', 'abfss://eo000extdb1@oneenvadls.dfs.core.windows.net/']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCreating external locations if they do not exist for the schemas based on the input dictionary.\u001b[0m\n",
      "   External location eo000_ext_db_loc01 already exists and will be used for db1.\u001b[0m\n",
      "   External location eo000_ext_db_loc01 already exists and will be used for db2.\u001b[0m\n",
      "   External location eo000_ext_db_loc02 already exists and will be used for db_empty.\u001b[0m\n",
      "\u001b[36mCreating data assets if they do not exist and migrate permissions, comments and tags.\u001b[0m\n",
      "   External location eo000_ext_loc_ctg5 already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n",
      "      Catalog eo000_ctg_ext_loc5 already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n",
      "         Schema db1 already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n",
      "            Table tbl1 already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n",
      "            Table tbl1_new already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n",
      "         Schema db2 already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n",
      "         Schema db_empty already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n",
      "         Schema db_ext already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n",
      "            Table tblx already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n",
      "         Schema db_other_assets already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n",
      "            Creating Table tbl1 and transferring permissions, comments and tags ...\u001b[0m User does not have USE SCHEMA on Schema 'eo000_ctg_ext_loc2.db_other_assets'.\n",
      "            Creating Table tbl2 and transferring permissions, comments and tags ...\u001b[0m User does not have USE SCHEMA on Schema 'eo000_ctg_ext_loc2.db_other_assets'.\n",
      "            Creating Table valid_groups and transferring permissions, comments and tags ...\u001b[0m User does not have USE SCHEMA on Schema 'eo000_ctg_ext_loc2.db_other_assets'.\n",
      "         Schema default already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n",
      "         Schema information_schema already exists. Only transferring permissions, comments and tags ...\u001b[0m \u001b[32mDONE!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "migrate = MigrateCatalog(**inputs, db_dict=db_dict)\n",
    "migrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salam\u001b[0m \u001b[43m\u001b[31msalam\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cprint('salam', end=' ')\n",
    "cprint('salam', color='red', on_color='on_yellow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databricks-sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
